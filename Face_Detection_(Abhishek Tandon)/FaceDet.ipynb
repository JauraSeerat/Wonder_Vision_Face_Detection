{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceDet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JauraSeerat/Wonder_Vision_Face_Detection/blob/master/Face_Detection_(Abhishek%20Tandon)/FaceDet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BvwjLZ9y_Uy",
        "colab_type": "text"
      },
      "source": [
        "A Colab notebook to test various face detection models. \n",
        "\n",
        "Models tested -- \n",
        "1. OpenCV HAAR Classifier \n",
        "2. OpenCV LBP Classifier \n",
        "3. dlib HOG Classifier\n",
        "4. OpenCV DNN Classifier - A ResNet10 based model.\n",
        "5. dlib DNN Classifier \n",
        "6. cvlib -- A tensorflow based face detection library\n",
        "6. Face Evolve \n",
        "\n",
        "The first row in the results show the model's performance on the images as it is. \n",
        "The second row in the results show the model's performance on the images which are first resized to (224 x 224) resolution size. \n",
        "\n",
        "Two models seem to perform really well on various images --\n",
        "\n",
        "a. OpenCV DNN Classifier -- Provides almost accurate bounding box over the images when images are first resized to (224 x 224)\n",
        "\n",
        "b. Face Evolve Classifier -- Based on MTCNN network this also provides almost accurate bounding box predictions. This also provides face landmarks information. \n",
        "\n",
        "\n",
        "Note -- \n",
        "1. Some of these images are taken from google for testing purposes. No copyright held by me. \n",
        "2. Scroll on the output block of the cells to see the results on various images \n",
        "\n",
        "Resources -- \n",
        "1. Face Evolve -- https://github.com/ZhaoJ9014/face.evoLVe.PyTorch \n",
        "2.  OpenCV -- https://github.com/opencv/opencv\n",
        "3. Blog for implemnting OpenCV HAAR and LBP Classifiers  https://www.superdatascience.com/blogs/opencv-face-detection\n",
        "4. Blog for implemnting OpenCV DNN, Dlib HOG and Dlib CNN Classifiers https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/\n",
        "5. Cvlib documentation http://cvlib.net\n",
        "6. MTCNN Paper: https://arxiv.org/pdf/1604.02878.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvLiy0Jofwqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j40ATWZ7htIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWPFK_yQg1cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make directory to hold all the files required for varioud models \n",
        "!mkdir ./face_det\n",
        "!ls ./face_det/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH7m3szIdymR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get all the files related to various models and store them in the face_det directory created in the last step \n",
        "\n",
        "#getting OpenCV DNN model config file \n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/opencv_face_detector.pbtxt -O ./face_det/opencv_face_detector.pbtxt  \n",
        "#getting OpenCV DNN model weights \n",
        "!wget https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180220_uint8/opencv_face_detector_uint8.pb -O ./face_det/opencv_face_detector_uint8.pb\n",
        "\n",
        "#getting dlib DNN face detector weights  \n",
        "!wget https://github.com/davisking/dlib-models/raw/master/mmod_human_face_detector.dat.bz2 -O ./face_det/mmod_human_face_detector.dat.bz2\n",
        "#unzipping the weight file\n",
        "!bzip2 -d ./face_det/mmod_human_face_detector.dat.bz2  \n",
        "\n",
        "#getting OpenCV HAAR Cascade Classifier model file \n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades_cuda/haarcascade_frontalface_alt.xml -O ./face_det/haarcascade_frontalface_alt.xml\n",
        "  \n",
        "#getting OpenCV LBP Cascade Classifier model file \n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/lbpcascades/lbpcascade_frontalface_improved.xml -O ./face_det/lbpcascade_frontalface_improved.xml\n",
        "  \n",
        "#install cvlib -- a tensorflow based face detection library \n",
        "!pip install cvlib  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS-wO_PWfVl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Listing the face_det directory contents \n",
        "!ls ./face_det/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37hHrmoHRgiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#OpenCV Haar Classifier\n",
        "\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt \n",
        "import time\n",
        "\n",
        "\n",
        "#Change the img_path as per your folder -- Parent folder containing all the images listed in img_list\n",
        "img_path = \"/content/drive/My Drive//Colab//privateAI//Face//data//\"\n",
        "\n",
        "#List of all images on which the classifier needs to be tested \n",
        "img_list = ['day7.png','day9.png','day11.png','day13.png','face1.jpg','face2.jpg','face3.jpeg','face4.jpg','face5.jpeg','face6.jpg','face7.jpeg','face8.jpg','face9.jpeg','face10.jpeg','face11.jpg']\n",
        "num_imgs = len(img_list)\n",
        "\n",
        "#Creating a grid to visualize results of size 2 X num_imgs\n",
        "gridsize = (2,num_imgs)\n",
        "fig = plt.figure(figsize=(80,10))\n",
        "plt.subplots_adjust(wspace=0.5,hspace=0.3)\n",
        "\n",
        "#Loadign the HAAR Face Cascade Classifier Model file \n",
        "haar_face_cascade = cv2.CascadeClassifier('./face_det/haarcascade_frontalface_alt.xml')\n",
        "\n",
        "\n",
        "time_normal = 0\n",
        "image_list_normal = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB)\n",
        "  H,W = image.shape[:2]\n",
        "  img_gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "  faces = haar_face_cascade.detectMultiScale(img_gray)\n",
        "  for face in faces:\n",
        "    cv2.rectangle(image, (face[0], face[1]), (face[0] + face[2],face[1] + face[3]),(255,0,0),4) \n",
        "  t2 = time.time()\n",
        "  time_normal = time_normal + (t2-t1)\n",
        "  image_list_normal.append(image)\n",
        "time_normal = round(time_normal/num_imgs,3)\n",
        "  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (0, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_normal[i])\n",
        "  \n",
        "\n",
        "time_resized = 0\n",
        "image_list_resized = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.resize(cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB),(224,224))\n",
        "  H,W = image.shape[:2]\n",
        "  img_gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "  faces = haar_face_cascade.detectMultiScale(img_gray)\n",
        "  for face in faces:\n",
        "    cv2.rectangle(image, (face[0], face[1]), (face[0] + face[2],face[1] + face[3]),(255,0,0),4) \n",
        "  t2 = time.time()\n",
        "  time_resized = time_resized + (t2-t1)\n",
        "  image_list_resized.append(image)\n",
        "time_resized = round(time_resized/num_imgs,3)  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (1, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_resized[i])  \n",
        "\n",
        "print (\"avg. time normal = %r  (secs) , avg. time resized = %r  (secs) \" %(time_normal,time_resized))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53caBmMuY3je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#OpenCV LBP Classifier\n",
        "\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt \n",
        "import time\n",
        "\n",
        "#Change the img_path as per your folder -- Parent folder containing all the images listed in img_list\n",
        "img_path = \"/content/drive/My Drive//Colab//privateAI//Face//data//\"\n",
        "#List of all images on which the classifier needs to be tested \n",
        "img_list = ['day7.png','day9.png','day11.png','day13.png','face1.jpg','face2.jpg','face3.jpeg','face4.jpg','face5.jpeg','face6.jpg','face7.jpeg','face8.jpg','face9.jpeg','face10.jpeg','face11.jpg']\n",
        "num_imgs = len(img_list)\n",
        "\n",
        "\n",
        "#Creating a grid to visualize results of size 2 X num_imgs\n",
        "gridsize = (2,num_imgs)\n",
        "fig = plt.figure(figsize=(80,10))\n",
        "plt.subplots_adjust(wspace=0.5,hspace=0.3)\n",
        "\n",
        "\n",
        "#Loading OpenCV LBP Classifier Model file \n",
        "lbp_face_cascade = cv2.CascadeClassifier('./face_det/lbpcascade_frontalface_improved.xml')\n",
        "\n",
        "\n",
        "time_normal = 0\n",
        "image_list_normal = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB)\n",
        "  H,W = image.shape[:2]\n",
        "  img_gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "  faces = lbp_face_cascade.detectMultiScale(img_gray)\n",
        "  for face in faces:\n",
        "    cv2.rectangle(image, (face[0], face[1]), (face[0] + face[2],face[1] + face[3]),(255,0,0),4) \n",
        "  t2 = time.time()\n",
        "  time_normal = time_normal + (t2-t1)\n",
        "  image_list_normal.append(image)\n",
        "time_normal = round(time_normal/num_imgs,3)\n",
        "  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (0, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_normal[i])\n",
        "  \n",
        "\n",
        "time_resized = 0\n",
        "image_list_resized = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.resize(cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB),(224,224))\n",
        "  H,W = image.shape[:2]\n",
        "  img_gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "  faces = lbp_face_cascade.detectMultiScale(img_gray)\n",
        "  for face in faces:\n",
        "    cv2.rectangle(image, (face[0], face[1]), (face[0] + face[2],face[1] + face[3]),(255,0,0),4)\n",
        "  t2 = time.time()\n",
        "  time_resized = time_resized + (t2-t1)\n",
        "  image_list_resized.append(image)\n",
        "time_resized = round(time_resized/num_imgs,3)  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (1, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_resized[i])  \n",
        "\n",
        "print (\"avg. time normal = %r  (secs) , avg. time resized = %r  (secs) \" %(time_normal,time_resized))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJr9QYKovu-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dlib HOG detector \n",
        "\n",
        "\n",
        "import dlib \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt \n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "#Change the img_path as per your folder -- Parent folder containing all the images listed in img_list \n",
        "img_path = \"/content/drive/My Drive//Colab//privateAI//Face//data//\"\n",
        "#List of all images on which the classifier needs to be tested \n",
        "img_list = ['day7.png','day9.png','day11.png','day13.png','face1.jpg','face2.jpg','face3.jpeg','face4.jpg','face5.jpeg','face6.jpg','face7.jpeg','face8.jpg','face9.jpeg','face10.jpeg','face11.jpg']\n",
        "num_imgs = len(img_list)\n",
        "\n",
        "\n",
        "#Creating a grid to visualize results of size 2 X num_imgs\n",
        "gridsize = (2,num_imgs)\n",
        "fig = plt.figure(figsize=(80,10))\n",
        "plt.subplots_adjust(wspace=0.5,hspace=0.3)\n",
        "\n",
        "#Creating an instance of dlib HOG Face Detector \n",
        "hogFaceDetector = dlib.get_frontal_face_detector()\n",
        "\n",
        "time_normal = 0\n",
        "image_list_normal = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB)\n",
        "  H,W = image.shape[:2]\n",
        "  detections = hogFaceDetector(image,1)\n",
        "  for face_rect in detections:\n",
        "    x1 = face_rect.left()\n",
        "    y1 = face_rect.top()\n",
        "    x2 = face_rect.right()\n",
        "    y2 = face_rect.bottom()\n",
        "    cv2.rectangle(image, (x1, y1), (x2,y2),(255,0,0),4)\n",
        "  t2 = time.time()\n",
        "  time_normal = time_normal + (t2-t1)\n",
        "  image_list_normal.append(image)\n",
        "time_normal = round(time_normal/num_imgs,3)\n",
        "  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (0, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_normal[i])\n",
        "  \n",
        "\n",
        "time_resized = 0\n",
        "image_list_resized = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.resize(cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB),(224,224))\n",
        "  H,W = image.shape[:2]\n",
        "  detections = hogFaceDetector(image,1)\n",
        "  for face_rect in detections:\n",
        "    x1 = face_rect.left()\n",
        "    y1 = face_rect.top()\n",
        "    x2 = face_rect.right()\n",
        "    y2 = face_rect.bottom()\n",
        "    cv2.rectangle(image, (x1, y1), (x2,y2),(255,0,0),4)\n",
        "  t2 = time.time()\n",
        "  time_resized = time_resized + (t2-t1)\n",
        "  image_list_resized.append(image)\n",
        "time_resized = round(time_resized/num_imgs,3)  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (1, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_resized[i])  \n",
        "\n",
        "print (\"avg. time normal = %r  (secs) , avg. time resized = %r  (secs) \" %(time_normal,time_resized))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmaEB43KhPfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#OpenCV DNN Face Detection \n",
        "\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt \n",
        "import time \n",
        "\n",
        "\n",
        "#Change the img_path as per your folder -  Parent folder containing all the images listed in img_list\n",
        "img_path = \"/content/drive/My Drive//Colab//privateAI//Face//data//\"\n",
        "#List of all images on which the classifier needs to be tested \n",
        "img_list = ['day7.png','day9.png','day11.png','day13.png','face1.jpg','face2.jpg','face3.jpeg','face4.jpg','face5.jpeg','face6.jpg','face7.jpeg','face8.jpg','face9.jpeg','face10.jpeg','face11.jpg']\n",
        "num_imgs = len(img_list)\n",
        "\n",
        "\n",
        "#Creating a grid to visualize results of size 2 X num_imgs\n",
        "gridsize = (2,num_imgs)\n",
        "fig = plt.figure(figsize=(80,10))\n",
        "plt.subplots_adjust(wspace=0.5,hspace=0.3)\n",
        "\n",
        "\n",
        "#Loading weights and config file of OpenCV DNN Classifier \n",
        "model_weights = \"./face_det/opencv_face_detector_uint8.pb\"\n",
        "model_config = \"./face_det/opencv_face_detector.pbtxt\"\n",
        "net = cv2.dnn.readNetFromTensorflow(model_weights,model_config)\n",
        "conf_thresh = 0.5\n",
        "\n",
        "time_normal = 0\n",
        "image_list_normal = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB)\n",
        "  H,W = image.shape[:2]\n",
        "  image_blob = cv2.dnn.blobFromImage(image,1.0,(300,300),(104.0, 177.0, 123.0))\n",
        "  net.setInput(image_blob)\n",
        "  detections = net.forward()\n",
        "  for i in range(detections.shape[2]):\n",
        "    confidence = float(detections[:,:,i,2])\n",
        "    if confidence > conf_thresh:\n",
        "      x1 = int(detections[:,:,i,3] * W)\n",
        "      y1 = int(detections[:,:,i,4] * H)\n",
        "      x2 = int(detections[:,:,i,5] * W)\n",
        "      y2 = int(detections[:,:,i,6] * H)\n",
        "      y = y1 - 10 if (y1 - 10) > 10 else y1 + 10\n",
        "      cv2.rectangle(image, (x1, y1), (x2,y2),(255, 0,0), 4)\n",
        "  t2 = time.time()\n",
        "  time_normal = time_normal + (t2-t1)\n",
        "  image_list_normal.append(image)\n",
        "time_normal = round(time_normal/num_imgs,3)\n",
        "  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (0, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_normal[i])\n",
        "  \n",
        "\n",
        "time_resized = 0\n",
        "image_list_resized = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.resize(cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB),(224,224))\n",
        "  H,W = image.shape[:2]\n",
        "  image_blob = cv2.dnn.blobFromImage(image,1.0,(300,300),(104.0, 177.0, 123.0))\n",
        "  net.setInput(image_blob)\n",
        "  detections = net.forward()\n",
        "  for i in range(detections.shape[2]):\n",
        "    confidence = float(detections[:,:,i,2])\n",
        "    if confidence > conf_thresh:\n",
        "      x1 = int(detections[:,:,i,3] * W)\n",
        "      y1 = int(detections[:,:,i,4] * H)\n",
        "      x2 = int(detections[:,:,i,5] * W)\n",
        "      y2 = int(detections[:,:,i,6] * H)\n",
        "      cv2.rectangle(image, (x1, y1), (x2,y2),(255,0,0), 4)\n",
        "  t2 = time.time()\n",
        "  time_resized = time_resized + (t2-t1)\n",
        "  image_list_resized.append(image)\n",
        "time_resized = round(time_resized/num_imgs,3)  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (1, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_resized[i])  \n",
        "\n",
        "print (\"avg. time normal = %r  (secs) , avg. time resized = %r  (secs) \" %(time_normal,time_resized))\n",
        "\n",
        "\n",
        "\n",
        "#Performs really well on resized images \n",
        "                           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48pFRVXC0VG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dlib CNN face detector \n",
        "\n",
        "\n",
        "import dlib\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "#Change the img_path as per your folder -  Parent folder containing all the images listed in img_list\n",
        "img_path = \"/content/drive/My Drive//Colab//privateAI//Face//data//\"\n",
        "#List of all images on which the classifier needs to be tested \n",
        "img_list = ['day7.png','day9.png','day11.png','day13.png','face1.jpg','face2.jpg','face3.jpeg','face4.jpg','face5.jpeg','face6.jpg','face7.jpeg','face8.jpg','face9.jpeg','face10.jpeg','face11.jpg']\n",
        "num_imgs = len(img_list)\n",
        "\n",
        "\n",
        "#Creating a grid to visualize results of size 2 X num_imgs\n",
        "gridsize = (2,num_imgs)\n",
        "fig = plt.figure(figsize=(80,10))\n",
        "plt.subplots_adjust(wspace=0.5,hspace=0.3)\n",
        "\n",
        "\n",
        "#Creating an instance of Dlib CNN Face Detector Model\n",
        "cnnFaceDetector = dlib.cnn_face_detection_model_v1(\"./face_det/mmod_human_face_detector.dat\")\n",
        "\n",
        "time_normal = 0\n",
        "image_list_normal = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB)\n",
        "  H,W = image.shape[:2]\n",
        "  detections = cnnFaceDetector(image,1)\n",
        "  for face_rect in detections:\n",
        "    x1 = face_rect.rect.left()\n",
        "    y1 = face_rect.rect.top()\n",
        "    x2 = face_rect.rect.right()\n",
        "    y2 = face_rect.rect.bottom()\n",
        "    cv2.rectangle(image, (x1, y1), (x2,y2),(255,0,0),4)\n",
        "  t2 = time.time()\n",
        "  time_normal = time_normal + (t2-t1)\n",
        "  image_list_normal.append(image)\n",
        "time_normal = round(time_normal/num_imgs,3)\n",
        "  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (0, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_normal[i])\n",
        "  \n",
        "\n",
        "time_resized = 0\n",
        "image_list_resized = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.resize(cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB),(224,224))\n",
        "  H,W = image.shape[:2]\n",
        "  detections = cnnFaceDetector(image,1)\n",
        "  for face_rect in detections:\n",
        "    x1 = face_rect.rect.left()\n",
        "    y1 = face_rect.rect.top()\n",
        "    x2 = face_rect.rect.right()\n",
        "    y2 = face_rect.rect.bottom()\n",
        "    cv2.rectangle(image, (x1, y1), (x2,y2),(255,0,0),4)\n",
        "  t2 = time.time()\n",
        "  time_resized = time_resized + (t2-t1)\n",
        "  image_list_resized.append(image)\n",
        "time_resized = round(time_resized/num_imgs,3)  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (1, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_resized[i])  \n",
        "\n",
        "print (\"avg. time normal = %r  (secs) , avg. time resized = %r  (secs) \" %(time_normal,time_resized))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBsMyJ103TZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cvlib Face Detector -- a library based on tensorflow \n",
        "\n",
        "import cvlib as cv \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time \n",
        "\n",
        "#Change the img_path as per your folder -  Parent folder containing all the images listed in img_list\n",
        "img_path = \"/content/drive/My Drive//Colab//privateAI//Face//data//\"\n",
        "#List of all images on which the classifier needs to be tested \n",
        "img_list = ['day7.png','day9.png','day11.png','day13.png','face1.jpg','face2.jpg','face3.jpeg','face4.jpg','face5.jpeg','face6.jpg','face7.jpeg','face8.jpg','face9.jpeg','face10.jpeg','face11.jpg']\n",
        "num_imgs = len(img_list)\n",
        "\n",
        "\n",
        "#Creating a grid to visualize results of size 2 X num_imgs\n",
        "gridsize = (2,num_imgs)\n",
        "fig = plt.figure(figsize=(80,10))\n",
        "plt.subplots_adjust(wspace=0.5,hspace=0.3)\n",
        "\n",
        "\n",
        "time_normal = 0\n",
        "image_list_normal = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB)\n",
        "  H,W = image.shape[:2]\n",
        "  faces, confidences = cv.detect_face(image)\n",
        "  for face in faces:\n",
        "    cv2.rectangle(image, (face[0], face[1]), (face[2],face[3]),(255,0,0),4) \n",
        "  t2 = time.time()\n",
        "  time_normal = time_normal + (t2-t1)\n",
        "  image_list_normal.append(image)\n",
        "time_normal = round(time_normal/num_imgs,3)\n",
        "  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (0, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_normal[i])\n",
        "  \n",
        "\n",
        "time_resized = 0\n",
        "image_list_resized = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = cv2.resize(cv2.cvtColor(cv2.imread(img_path + img_name),cv2.COLOR_BGR2RGB),(224,224))\n",
        "  H,W = image.shape[:2]\n",
        "  faces, confidences = cv.detect_face(image)\n",
        "  for face in faces:\n",
        "    cv2.rectangle(image, (face[0], face[1]), (face[2],face[3]),(255,0,0),4) \n",
        "  t2 = time.time()\n",
        "  time_resized = time_resized + (t2-t1)\n",
        "  image_list_resized.append(image)\n",
        "time_resized = round(time_resized/num_imgs,3)  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (1, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_resized[i])  \n",
        "\n",
        "print (\"avg. time normal = %r  (secs) , avg. time resized = %r  (secs) \" %(time_normal,time_resized))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaje3f5jXps8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting files require to run Face Evolve model based on MTCNN for Face Detection \n",
        "\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/align_trans.py -O ./align_trans.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/box_utils.py -O ./box_utils.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/detector.py -O ./detector.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/face_align.py -O ./face_align.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/face_resize.py -O ./face_resize.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/first_stage.py -O ./first_stage.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/get_nets.py -O ./get_nets.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/matlab_cp2tform.py -O ./matlab.cpt2tform.py\n",
        "  \n",
        "#Getting the weights of three models Onet, Pnet and Rnet \n",
        "!wget https://github.com/ZhaoJ9014/face.evoLVe.PyTorch/raw/master/align/onet.npy -O ./onet.npy\n",
        "!wget https://github.com/ZhaoJ9014/face.evoLVe.PyTorch/raw/master/align/pnet.npy -O ./pnet.npy\n",
        "!wget https://github.com/ZhaoJ9014/face.evoLVe.PyTorch/raw/master/align/rnet.npy -O ./rnet.npy\n",
        "  \n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/visualization_utils.py -O ./visualization_utils.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvcZl_CUXElZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Face Evolve -- Pytorch \n",
        "\n",
        "from PIL import Image \n",
        "from detector import detect_faces\n",
        "from visualization_utils import show_results\n",
        "import matplotlib.pyplot as plt \n",
        "import time\n",
        "\n",
        "\n",
        "#Change the img_path as per your folder -  Parent folder containing all the images listed in img_list\n",
        "img_path = \"/content/drive/My Drive//Colab//privateAI//Face//data//\"\n",
        "#List of all images on which the classifier needs to be tested \n",
        "img_list = ['face1.jpg','face2.jpg','face3.jpeg','face4.jpg','face5.jpeg','face6.jpg','face7.jpeg','face8.jpg','face9.jpeg','face10.jpeg','face11.jpg']\n",
        "num_imgs = len(img_list)\n",
        "\n",
        "\n",
        "#Creating a grid to visualize results of size 2 X num_imgs\n",
        "gridsize = (2,num_imgs)\n",
        "fig = plt.figure(figsize=(80,10))\n",
        "plt.subplots_adjust(wspace=0.5,hspace=0.3)\n",
        "\n",
        "\n",
        "time_normal = 0\n",
        "image_list_normal = list()\n",
        "for k,img_name in enumerate(img_list):\n",
        "  t1 = time.time()\n",
        "  image = Image.open(img_path + img_name)\n",
        "  #H,W = image.shape[:2]\n",
        "  bounding_boxes, landmarks = detect_faces(image)\n",
        "  img_res = show_results(image, bounding_boxes, landmarks)    \n",
        "  t2 = time.time()\n",
        "  time_normal = time_normal + (t2-t1)\n",
        "  image_list_normal.append(img_res)\n",
        "time_normal = round(time_normal/num_imgs,3)\n",
        "  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (0, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_normal[i])\n",
        "  \n",
        "\n",
        "time_resized = 0\n",
        "image_list_resized = list()\n",
        "for img_name in img_list:\n",
        "  t1 = time.time()\n",
        "  image = Image.open(img_path + img_name)\n",
        "  image = image.resize((224,224), Image.ANTIALIAS)\n",
        "  #H,W = image.shape[:2]\n",
        "  bounding_boxes, landmarks = detect_faces(image)\n",
        "  img_res = show_results(image, bounding_boxes, landmarks) \n",
        "  t2 = time.time()\n",
        "  time_resized = time_resized + (t2-t1)\n",
        "  image_list_resized.append(img_res)\n",
        "time_resized = round(time_resized/num_imgs,3)  \n",
        "  \n",
        "for i in range(num_imgs):\n",
        "  ax = plt.subplot2grid(gridsize, (1, i))\n",
        "  ax.grid(False)\n",
        "  ax.imshow(image_list_resized[i])  \n",
        "\n",
        "print (\"avg. time normal = %r  (secs) , avg. time resized = %r  (secs) \" %(time_normal,time_resized))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUeMyo35E8Na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing OpenCV DNN Classifier on a video -- Video available at https://www.videvo.net/video/woman-carrying-basket-on-head/7525/\n",
        "\n",
        "import imutils\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#Load the face video as per your directory path \n",
        "vs = cv2.VideoCapture('/content/drive/My Drive//Colab//privateAI//Face//data//facevid.mp4')\n",
        "writer = None\n",
        "(W, H) = (None, None)\n",
        "\n",
        "\n",
        "while True:\n",
        "  (grabbed, frame) = vs.read()\n",
        "  if not grabbed:\n",
        "    break\n",
        "  #image = cv2.resize(frame,(224,224))    \n",
        "  image = frame\n",
        "  H,W = image.shape[:2]\n",
        "  image_blob = cv2.dnn.blobFromImage(image,1.0,(300,300),(104.0, 177.0, 123.0))\n",
        "  net.setInput(image_blob)\n",
        "  detections = net.forward()\n",
        "  for i in range(detections.shape[2]):\n",
        "    confidence = float(detections[:,:,i,2])\n",
        "    if confidence > conf_thresh:\n",
        "      x1 = int(detections[:,:,i,3] * W)\n",
        "      y1 = int(detections[:,:,i,4] * H)\n",
        "      x2 = int(detections[:,:,i,5] * W)\n",
        "      y2 = int(detections[:,:,i,6] * H)\n",
        "      cv2.rectangle(image, (x1, y1), (x2,y2),(255,0,0), 4)\n",
        "  if writer is None:\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "    \n",
        "    #saving the frame of the video at the desired path \n",
        "    writer = cv2.VideoWriter('/content/drive/My Drive//Colab//privateAI//Face//data//outvid1.avi', fourcc, 30,(image.shape[1], image.shape[0]), True)  \n",
        "  writer.write(image)\n",
        "writer.release()\n",
        "vs.release() \n",
        "print ('done')  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}