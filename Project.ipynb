{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProject.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JauraSeerat/Wonder_Vision_Face_Detection/blob/master/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJpfgjbBol27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtQHVG9Xl1QP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download Face evolve model files \n",
        "\n",
        "#Getting files require to run Face Evolve model based on MTCNN for Face Detection \n",
        "\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/align_trans.py -O ./align_trans.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/box_utils.py -O ./box_utils.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/detector.py -O ./detector.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/face_align.py -O ./face_align.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/face_resize.py -O ./face_resize.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/first_stage.py -O ./first_stage.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/get_nets.py -O ./get_nets.py\n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/matlab_cp2tform.py -O ./matlab.cpt2tform.py\n",
        "  \n",
        "#Getting the weights of three models Onet, Pnet and Rnet \n",
        "!wget https://github.com/ZhaoJ9014/face.evoLVe.PyTorch/raw/master/align/onet.npy -O ./onet.npy\n",
        "!wget https://github.com/ZhaoJ9014/face.evoLVe.PyTorch/raw/master/align/pnet.npy -O ./pnet.npy\n",
        "!wget https://github.com/ZhaoJ9014/face.evoLVe.PyTorch/raw/master/align/rnet.npy -O ./rnet.npy\n",
        "  \n",
        "!wget https://raw.githubusercontent.com/ZhaoJ9014/face.evoLVe.PyTorch/master/align/visualization_utils.py -O ./visualization_utils.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QpzivaGHvS_B",
        "colab": {}
      },
      "source": [
        "#Main code \n",
        "\n",
        "from google.colab import files \n",
        "\n",
        "#Python Imports\n",
        "from PIL import Image \n",
        "from detector import detect_faces\n",
        "import matplotlib.pyplot as plt \n",
        "import time\n",
        "import numpy as np \n",
        "import warnings\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#model_path = \"/content/drive/My Drive//Colab//privateAI//Face//model//model.pt\"\n",
        "model_path = \"/content/drive/My Drive//Colab//privateAI//Face//model//model.pt\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "tensor_transform = transforms.ToTensor()\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(1, 4, kernel_size=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(4),\n",
        "            \n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(4, 8, kernel_size=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(8),\n",
        "\n",
        "\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(8, 8, kernel_size=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(8),\n",
        "\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(8*100*100, 500),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(500, 500),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(500, 5))\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2\n",
        "      \n",
        "      \n",
        "recognition_model = SiameseNetwork().to(device)\n",
        "recognition_model.load_state_dict(torch.load(model_path))\n",
        "recognition_model = recognition_model.to(\"cpu\")\n",
        "recognition_model = recognition_model.to(device)\n",
        "\n",
        "\n",
        "def compare_faces(first_image,second_image):\n",
        "  first_image = first_image.resize((100,100), Image.ANTIALIAS).convert('L')  \n",
        "  second_image = second_image.resize((100,100), Image.ANTIALIAS).convert('L')   \n",
        "  first_image_tensor = tensor_transform(first_image).unsqueeze(0).to(device)\n",
        "  second_image_tensor = tensor_transform(second_image).unsqueeze(0).to(device)\n",
        "  output_first,output_second = recognition_model(first_image_tensor,second_image_tensor)\n",
        "  with torch.no_grad():\n",
        "    similarity_score = 1 - F.pairwise_distance(output_first, output_second)  \n",
        "  return similarity_score\n",
        "\n",
        "def face_detection(image):\n",
        "  bounding_box = detect_faces(image)\n",
        "  cropped_image = image.crop((bounding_box[0][0][0],bounding_box[0][0][1],bounding_box[0][0][2],bounding_box[0][0][3]))\n",
        "  return cropped_image\n",
        "\n",
        "\n",
        "def get_similarity_score(first_image_path,second_image_path):\n",
        "  first_image = Image.open(first_image_path).resize((255,255), Image.ANTIALIAS) \n",
        "  first_image_cropped = face_detection(first_image)\n",
        "  second_image = Image.open(second_image_path).resize((255,255), Image.ANTIALIAS) \n",
        "  second_image_cropped = face_detection(second_image)\n",
        "  similarity_score = compare_faces(first_image_cropped,second_image_cropped)\n",
        "  similarity_score = similarity_score[0].to(\"cpu\").numpy()\n",
        "  return similarity_score,first_image,second_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrivFh5fmn_9",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Upload images\n",
        "#Upload first image\n",
        "\n",
        "print ('Hello User! Please upload first image')\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  first_image_path = \"./\" + fn\n",
        "  \n",
        "  \n",
        "print ('Please upload the second image')  \n",
        "#Upload second image\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  second_image_path = \"./\" + fn\n",
        "  \n",
        "  \n",
        "# first_image_path = \"./face3.jpg\"  \n",
        "# second_image_path = \"./face4.jpg\"\n",
        "gridsize = (1,2)\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "plt.subplots_adjust(wspace=0.5,hspace=0.05)\n",
        "\n",
        "print ('Calculating the similarity score... Please wait for a moment')\n",
        "\n",
        "sc,first_image,second_image = get_similarity_score(first_image_path,second_image_path)\n",
        "print ('completed')\n",
        "\n",
        "\n",
        "print ('\\n\\n\\nSimilarity Score is %.2f' %(sc))\n",
        "ax = plt.subplot2grid(gridsize, (0,0))\n",
        "ax.grid(False)\n",
        "ax.set_title(\"First Image\")\n",
        "ax.imshow(first_image)  \n",
        "ax = plt.subplot2grid(gridsize, (0,1))\n",
        "ax.grid(False)\n",
        "ax.set_title(\"Second Image\")\n",
        "ax.imshow(second_image)  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}